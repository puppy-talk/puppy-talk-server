version: '3.8'

# 프로덕션용 Docker Compose 설정
# 보안, 성능, 모니터링에 최적화된 구성

services:
  # MySQL 데이터베이스 (프로덕션)
  mysql:
    container_name: puppy-talk-mysql-prod
    image: mysql:8.0.36
    restart: always
    environment:
      MYSQL_DATABASE: ${MYSQL_DATABASE}
      MYSQL_ROOT_PASSWORD: ${MYSQL_ROOT_PASSWORD}
      MYSQL_USER: ${MYSQL_USER}
      MYSQL_PASSWORD: ${MYSQL_PASSWORD}
      TZ: Asia/Seoul
    command:
      - --character-set-server=utf8mb4
      - --collation-server=utf8mb4_unicode_ci
      - --default-time-zone=+09:00
      - --sql-mode=STRICT_TRANS_TABLES,NO_ZERO_DATE,NO_ZERO_IN_DATE,ERROR_FOR_DIVISION_BY_ZERO
      - --max_connections=2000
      - --innodb-buffer-pool-size=1G
      - --innodb-log-file-size=256M
      - --innodb-flush-log-at-trx-commit=1
      - --sync-binlog=1
      - --binlog-format=ROW
      - --log-bin=mysql-bin
      - --server-id=1
      - --gtid-mode=ON
      - --enforce-gtid-consistency=ON
      - --log-slave-updates=ON
      - --binlog-checksum=CRC32
      - --master-verify-checksum=ON
      - --slave-sql-verify-checksum=ON
    volumes:
      - mysql_prod_data:/var/lib/mysql
      - mysql_prod_logs:/var/log/mysql
      - ./backup:/backup:ro
    healthcheck:
      test: ["CMD", "mysqladmin", "ping", "-h", "localhost", "--silent"]
      start_period: 30s
      interval: 15s
      timeout: 10s
      retries: 3
    networks:
      - puppy-talk-prod-network
    logging:
      driver: "json-file"
      options:
        max-size: "100m"
        max-file: "5"
    deploy:
      resources:
        limits:
          memory: 2G
          cpus: "1.0"
        reservations:
          memory: 1G
          cpus: "0.5"

  # Redis (프로덕션 - 캐싱 및 세션 저장용)
  redis:
    container_name: puppy-talk-redis-prod
    image: redis:7.2-alpine
    restart: always
    environment:
      TZ: Asia/Seoul
    command: >
      redis-server
      --appendonly yes
      --appendfsync everysec
      --maxmemory 512mb
      --maxmemory-policy allkeys-lru
      --tcp-keepalive 60
      --timeout 300
      --requirepass ${REDIS_PASSWORD}
    volumes:
      - redis_prod_data:/data
      - redis_prod_logs:/var/log/redis
    healthcheck:
      test: ["CMD", "redis-cli", "--no-auth-warning", "-a", "${REDIS_PASSWORD}", "ping"]
      interval: 15s
      timeout: 5s
      retries: 3
    networks:
      - puppy-talk-prod-network
    logging:
      driver: "json-file"
      options:
        max-size: "50m"
        max-file: "3"
    deploy:
      resources:
        limits:
          memory: 768M
          cpus: "0.5"
        reservations:
          memory: 256M
          cpus: "0.2"

  # Puppy Talk 애플리케이션 (프로덕션)
  app:
    container_name: puppy-talk-server-prod
    build:
      context: .
      dockerfile: Dockerfile
      args:
        - BUILD_DATE=${BUILD_DATE}
        - VCS_REF=${VCS_REF}
    restart: always
    environment:
      # Spring Profiles
      SPRING_PROFILES_ACTIVE: prod
      
      # Database Configuration
      SPRING_DATASOURCE_URL: jdbc:mysql://mysql:3306/${MYSQL_DATABASE}?useSSL=true&requireSSL=true&verifyServerCertificate=false&allowPublicKeyRetrieval=true&serverTimezone=Asia/Seoul
      SPRING_DATASOURCE_USERNAME: ${MYSQL_USER}
      SPRING_DATASOURCE_PASSWORD: ${MYSQL_PASSWORD}
      SPRING_DATASOURCE_HIKARI_MAXIMUM_POOL_SIZE: 20
      SPRING_DATASOURCE_HIKARI_MINIMUM_IDLE: 5
      SPRING_DATASOURCE_HIKARI_CONNECTION_TIMEOUT: 30000
      SPRING_DATASOURCE_HIKARI_IDLE_TIMEOUT: 600000
      SPRING_DATASOURCE_HIKARI_MAX_LIFETIME: 1800000
      
      # Redis Configuration
      SPRING_REDIS_HOST: redis
      SPRING_REDIS_PORT: 6379
      SPRING_REDIS_PASSWORD: ${REDIS_PASSWORD}
      SPRING_REDIS_TIMEOUT: 3000ms
      SPRING_REDIS_JEDIS_POOL_MAX_ACTIVE: 20
      SPRING_REDIS_JEDIS_POOL_MAX_IDLE: 10
      SPRING_REDIS_JEDIS_POOL_MIN_IDLE: 2
      
      # JVM Configuration
      JAVA_OPTS: >-
        -Xms1g
        -Xmx2g
        -XX:+UseG1GC
        -XX:+UseContainerSupport
        -XX:MaxRAMPercentage=75.0
        -XX:+HeapDumpOnOutOfMemoryError
        -XX:HeapDumpPath=/tmp/heapdump.hprof
        -XX:+UseStringDeduplication
        -XX:+OptimizeStringConcat
        -XX:+UseCompressedOops
        -XX:+UseCompressedClassPointers
        -Duser.timezone=Asia/Seoul
        -Dspring.profiles.active=prod
        -Djava.security.egd=file:/dev/./urandom
      
      # Application Configuration
      SERVER_PORT: 8080
      MANAGEMENT_SERVER_PORT: 8081
      MANAGEMENT_ENDPOINTS_WEB_EXPOSURE_INCLUDE: health,info,metrics,prometheus
      MANAGEMENT_ENDPOINT_HEALTH_SHOW_DETAILS: when-authorized
      MANAGEMENT_METRICS_EXPORT_PROMETHEUS_ENABLED: true
      
      # Security Configuration
      SERVER_SSL_ENABLED: false  # SSL terminated at nginx
      SERVER_USE_FORWARD_HEADERS: true
      
      # WebSocket Configuration
      PUPPY_TALK_WEBSOCKET_ALLOWED_ORIGINS: ${ALLOWED_ORIGINS}
      
      # Logging Configuration
      LOGGING_LEVEL_ROOT: WARN
      LOGGING_LEVEL_COM_PUPPY_TALK: INFO
      LOGGING_LEVEL_ORG_SPRINGFRAMEWORK_SECURITY: WARN
      LOGGING_PATTERN_FILE: "%d{yyyy-MM-dd HH:mm:ss.SSS} [%thread] %-5level [%logger{50}] - %msg%n"
      LOGGING_FILE_NAME: /application/logs/puppy-talk.log
      LOGGING_LOGBACK_ROLLINGPOLICY_MAX_FILE_SIZE: 100MB
      LOGGING_LOGBACK_ROLLINGPOLICY_TOTAL_SIZE_CAP: 1GB
      LOGGING_LOGBACK_ROLLINGPOLICY_MAX_HISTORY: 30
      
    depends_on:
      mysql:
        condition: service_healthy
      redis:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:8081/actuator/health"]
      start_period: 120s
      interval: 30s
      timeout: 10s
      retries: 3
    volumes:
      - app_prod_logs:/application/logs
      - app_prod_tmp:/tmp
    networks:
      - puppy-talk-prod-network
    logging:
      driver: "json-file"
      options:
        max-size: "200m"
        max-file: "5"
    deploy:
      resources:
        limits:
          memory: 3G
          cpus: "2.0"
        reservations:
          memory: 1G
          cpus: "0.5"
      replicas: 2
      update_config:
        parallelism: 1
        delay: 30s
        order: start-first
      restart_policy:
        condition: any
        delay: 5s
        max_attempts: 3
        window: 120s

  # Nginx (프로덕션 리버스 프록시)
  nginx:
    container_name: puppy-talk-nginx-prod
    image: nginx:1.25-alpine
    ports:
      - "80:80"
      - "443:443"
    restart: always
    environment:
      TZ: Asia/Seoul
    volumes:
      - ./nginx/nginx.prod.conf:/etc/nginx/nginx.conf:ro
      - ./nginx/conf.d:/etc/nginx/conf.d:ro
      - ./nginx/ssl:/etc/nginx/ssl:ro
      - nginx_prod_logs:/var/log/nginx
    depends_on:
      - app
    networks:
      - puppy-talk-prod-network
    logging:
      driver: "json-file"
      options:
        max-size: "100m"
        max-file: "5"
    deploy:
      resources:
        limits:
          memory: 512M
          cpus: "0.5"
        reservations:
          memory: 128M
          cpus: "0.1"

  # Prometheus (메트릭 수집)
  prometheus:
    container_name: puppy-talk-prometheus
    image: prom/prometheus:latest
    ports:
      - "9090:9090"
    restart: always
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
      - '--storage.tsdb.retention.time=15d'
      - '--web.enable-lifecycle'
      - '--web.enable-admin-api'
    volumes:
      - ./monitoring/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - prometheus_data:/prometheus
    networks:
      - puppy-talk-prod-network
    deploy:
      resources:
        limits:
          memory: 1G
          cpus: "0.5"

  # Grafana (메트릭 시각화)
  grafana:
    container_name: puppy-talk-grafana
    image: grafana/grafana:latest
    ports:
      - "3000:3000"
    restart: always
    environment:
      GF_SECURITY_ADMIN_PASSWORD: ${GRAFANA_ADMIN_PASSWORD}
      GF_INSTALL_PLUGINS: grafana-clock-panel,grafana-simple-json-datasource
    volumes:
      - grafana_data:/var/lib/grafana
      - ./monitoring/grafana/dashboards:/etc/grafana/provisioning/dashboards:ro
      - ./monitoring/grafana/datasources:/etc/grafana/provisioning/datasources:ro
    networks:
      - puppy-talk-prod-network
    depends_on:
      - prometheus
    deploy:
      resources:
        limits:
          memory: 512M
          cpus: "0.3"

volumes:
  mysql_prod_data:
    driver: local
  mysql_prod_logs:
    driver: local
  redis_prod_data:
    driver: local
  redis_prod_logs:
    driver: local
  app_prod_logs:
    driver: local
  app_prod_tmp:
    driver: local
  nginx_prod_logs:
    driver: local
  prometheus_data:
    driver: local
  grafana_data:
    driver: local

networks:
  puppy-talk-prod-network:
    driver: bridge
    ipam:
      config:
        - subnet: 172.22.0.0/16

# 프로덕션 환경 실행:
# 1. 환경변수 설정: .env.prod 파일 생성
# 2. SSL 인증서 준비: nginx/ssl/ 디렉토리에 배치
# 3. 서비스 시작: docker-compose -f docker-compose.prod.yml up -d
# 4. 로그 모니터링: docker-compose -f docker-compose.prod.yml logs -f
#
# 모니터링 대시보드:
# - Grafana: https://your-domain.com:3000 (admin/${GRAFANA_ADMIN_PASSWORD})
# - Prometheus: https://your-domain.com:9090